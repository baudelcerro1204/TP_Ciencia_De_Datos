import os
import time
from pathlib import Path

import pandas as pd
import numpy as np
from tqdm import tqdm

class MillionSongDataProcessor:
    def __init__(self):
        self.raw_path = Path('../data/raw')   # carpeta raw con los CSV
        self.processed_path = Path('../data/processed')  # carpeta para parquet procesado
        self.processed_path.mkdir(parents=True, exist_ok=True)

        # Archivos CSV originales
        self.music_info_file = self.raw_path / 'Music Info.csv'
        self.user_listening_file = self.raw_path / 'User Listening History.csv'

        # Archivo parquet combinado resultante
        self.processed_file = self.processed_path / 'million_song_combined.parquet'


    def safe_str_access(self, series, default=''):
        if series.dtype == object:
            return series.fillna(default).astype(str)
        return series.astype(str).fillna(default)

    def load_music_info(self) -> pd.DataFrame:
        print(f"ðŸ” Cargando Music Info desde {self.music_info_file}")
        df = pd.read_csv(self.music_info_file)
        print(f"   â†’ {len(df)} filas, columnas: {list(df.columns)}")
        return df

    def clean_music_info(self, df: pd.DataFrame) -> pd.DataFrame:
        # Limpieza bÃ¡sica
        df = df.drop_duplicates(subset=['track_id'])
        # Normalizar texto a lowercase para algunas columnas
        for col in ['artist', 'genre', 'name']:
            if col in df.columns:
                df[col] = self.safe_str_access(df[col]).str.lower().str.strip()
        print(f"ðŸ§¹ Music Info limpio: {len(df)} filas")
        return df

    def load_user_history(self) -> pd.DataFrame:
        print(f"ðŸ” Cargando User Listening History desde {self.user_listening_file}")
        df = pd.read_csv(self.user_listening_file)
        print(f"   â†’ {len(df)} filas, columnas: {list(df.columns)}")
        return df

    def combine_data(self, music_info: pd.DataFrame, user_hist: pd.DataFrame) -> pd.DataFrame:
        print("ðŸ”„ Combinando datasets por track_id")
        combined = user_hist.merge(music_info, left_on='track_id', right_on='track_id', how='left')
        print(f"   â†’ Data combinada tiene {len(combined)} filas y columnas {list(combined.columns)}")
        return combined

    def clean_unused_features(self, df: pd.DataFrame) -> pd.DataFrame:
        # Columnas a eliminar porque no sirven para la comparaciÃ³n
        cols_to_drop = [
            'valence', 'tempo', 'playcount', 'year', 'days_since_release',
            'mode', 'key', 'time_signature',
            'rhythm_mfcc_1', 'rhythm_mfcc_2', 'bit_rate'
        ]
        # Solo eliminar si existen en el df para evitar error
        cols_existing = [col for col in cols_to_drop if col in df.columns]
        if cols_existing:
            print(f"ðŸ—‘ Eliminando columnas no Ãºtiles para comparaciÃ³n: {cols_existing}")
            df = df.drop(columns=cols_existing)
        else:
            print("â„¹ï¸ No se encontraron columnas no Ãºtiles para eliminar.")
        return df

    def save_processed_data(self, df: pd.DataFrame) -> Path:
        df.to_parquet(self.processed_file, index=False)
        print(f"ðŸ’¾ Dataset combinado guardado en: {self.processed_file}")
        return self.processed_file

    def process_all(self) -> pd.DataFrame:
        music_info = self.load_music_info()
        music_info_clean = self.clean_music_info(music_info)

        user_hist = self.load_user_history()

        combined = self.combine_data(music_info_clean, user_hist)

        # AquÃ­ limpiamos las columnas que no usaremos para la comparaciÃ³n
        combined_clean = self.clean_unused_features(combined)

        self.save_processed_data(combined_clean)

        return combined_clean


if __name__ == '__main__':
    processor = MillionSongDataProcessor()
    df_final = processor.process_all()
    print("\nðŸ”Ž Vista previa del dataset combinado (limpio):")
    print(df_final.head(10))
